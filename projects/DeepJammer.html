<!DOCTYPE html>
<html lang="en">

<head>

    <base href="../">

    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="description" content="Deep Jammer">
    <meta name="author" content="Sam Witty">

    <title>Deep Jammer</title>

    <!-- Bootstrap Core CSS -->
    <link href="vendor/bootstrap/css/bootstrap.css" rel="stylesheet">

    <!-- Theme CSS -->
    <link href="css/clean-blog.css" rel="stylesheet">

    <!-- Custom Fonts -->
    <link href="vendor/font-awesome/css/font-awesome.min.css" rel="stylesheet" type="text/css">
    <link href='https://fonts.googleapis.com/css?family=Lora:400,700,400italic,700italic' rel='stylesheet' type='text/css'>
    <link href='https://fonts.googleapis.com/css?family=Open+Sans:300italic,400italic,600italic,700italic,800italic,400,300,600,700,800' rel='stylesheet' type='text/css'>

    <!-- HTML5 Shim and Respond.js IE8 support of HTML5 elements and media queries -->
    <!-- WARNING: Respond.js doesn't work if you view the page via file:// -->
    <!--[if lt IE 9]>
        <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
        <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
    <![endif]-->

</head>

<body>

    <!-- Navigation -->
    <nav class="navbar navbar-default navbar-custom navbar-fixed-top">
        <div class="container-fluid">
            <!-- Brand and toggle get grouped for better mobile display -->
            <div class="navbar-header page-scroll">
                <button type="button" class="navbar-toggle" data-toggle="collapse" data-target="#bs-example-navbar-collapse-1">
                    <span class="sr-only">Toggle navigation</span>
                    Menu <i class="fa fa-bars"></i>
                </button>
            </div>

            <!-- Collect the nav links, forms, and other content for toggling -->
            <div class="collapse navbar-collapse" id="bs-example-navbar-collapse-1">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="index.html">About</a>
                    </li>
                    <li>
                        <a href="projects.html">Projects</a>
                    </li>
                    <li>
                        <a href="blog/index.html">Blog</a>
                    </li>
                </ul>
            </div>
            <!-- /.navbar-collapse -->
        </div>
        <!-- /.container -->
    </nav>

    <!-- Page Header -->
    <!-- Set your background image for this header on the line below. -->
    <header class="intro-header" style="background-image: url('img/projects-bg.jpg')">
        <div class="container">
            <div class="row">
                <div class="site-heading">
                    <h1>PROJECTS</h1>
                </div>
            </div>
        </div>
    </header>
                
    <!-- Post Content -->
    <article>
        <div class="container">
            <div class="row">
                <div class="col-lg-10 col-lg-offset-1 col-md-10 col-md-offset-1">

                    <div class="post-preview">
                    <a href="projects.html#deepjammer">
                        <h2 class="post-title" id="start">
                              DEEP JAMMER
                        </h2>
                        <hr class="medium">
                        <h3 class="post-subtitle">
                            Deep Learning Music Composition
                        </h3>
                    </a>
                    <p class="post-meta">Posted on January 15, 2017</p>
                    </div>
                    
                    <p>Deep Jammer is an algorithm for composing original music segments using deep learning that <a href="http://www.justinsvegliato.com">Justin Svegliato</a> and I collaborated on as the final project for two graduate level machine learning courses at UMass Amherst, CS689 - Machine Learning and CS697L - Deep Learning.</p>

                    <h2 class="section-heading">Introduction</h2>

                    <p>Using machine learning to generate music is an inherently interesting task because it provides deep insight into the extent algorithms can represent human creativity. Unlike the common applications of deep learning for computer vision, which has a high degree of spatial invariance, or natural language processing, which has a high degree of temporal invariance, music inevitably includes both temporal and spatial invariances. This makes for a much more interesting technical challenge.</p>

                    <p> Motivation aside, here are some examples of the music composed by the deep-jammer algorithm. These music segments were generated after using a g2.2xlarge AWS EC2 instance to train the algorithm for approximately 5,000 epochs of 325 classical music compositions encoded as MIDI files.</p>

                    <audio controls>
                        <source src="audio/large network 1.mp3" type="audio/mpeg">
                    </audio>

                    <audio controls>
                        <source src="audio/large network 2.mp3" type="audio/mpeg">
                    </audio>

                    <audio controls>
                        <source src="audio/large network 3.mp3" type="audio/mpeg">
                    </audio>

                    <audio controls>
                        <source src="audio/large network 4.mp3" type="audio/mpeg">
                    </audio>

                    <h2 class="section-heading">Methodology</h2>

                    <p>While reinforcement learning methods are perhaps more consistent with how humans learn to compose music, the lack of a meaningful reward signal encouraged us to approach the task as a supervised problem using human-composed music as a training set. We used deep learning methods becauses of their ability to represent complex non-linear high-dimensional functions.</p>

                    <p>To make the network learn a bit faster, we engineered musical features from the raw MIDI training files. Given a set of these features corresponding to a single time step as input, the task of the neural network model is to predict the notes to be played at the next time step.</p>

                    <img src="img/Deep Jammer Input Output.png">

                    <p>The neural network architecture we explored is heavily inspired by Daniel Johnson's work on music generation, which can be found on his personal website <a href="http://www.hexahedria.com">hexahadria</a>. This architecture uses 2 distinct sets of recurrent layers (LSTMs) separated by a transpose layer to represent the temporal and spatial invariance of music. These two sets of LSTMs are called the time layers and the note layers.</p>

                    <img src="img/Deep Jammer Architecture.png">

                    <p>An intuitive way of thinking about this architecture is that the transpose layer flips a switch between the time and note dimensions of the input data. This effectively switches which dimension, time and note, is stored in memory at each of the layers. This transpose layer is the missing piece that allows the neural network to represent both temporal and spatial (note) invariance simulataneously.</p>

                    <p> Training is completed using back-propagation, where at each time step the model is predicting the notes played at the next time step given the input features and stored history. The loss is defined as the negative log-likelihood of the predicted notes, given the actual notes played at the next time-step. A typical loss curve is shown below.</p>

                    <img src="img/Deep Jammer Loss Curve.png">

                    <p>Composing music can be thought as recursive prediction given some random initialization. More precisely, notes are selected at each timestep by sampling from the output probabilities given the input features. Once selected, these notes are then used to generate features for the next time-step. This process is repeated until the algorithm terminates after a predetermined number of iterations.</p>

                    <p>The following graphic shows how the music generation deveops with increasing amounts of training. Each of the 4 compositions shown were generated using the network parameters at the corresponding stages in the loss curve. The network first learns the appropriate amount of sparsity, then learns basic musical structure, and finally converges to a network that produces human-like compositions.</p>

                     <img src="img/Deep Jammer Stages.png">

                    <p> Stage 5 and 6 on the loss curve show the effect of transfer learning to jazz music, which is discussed in detail in our report. </p>

                    <h2 class="section-heading">Further Reading</h2>

                    <p>In the interest of brevity I've omitted a large portion of the project work on alternative architectures, transfer learning, and analysis of survey results. If you're interesting in reading more please feel free to take a look at our full <a href="download/Deep Jammer Report.pdf" download="Deep Jammer Report">report</a> and <a href="download/Deep Jammer Poster.pdf" download="Deep Jammer Poster">poster</a>. You can also find the entire implementation using both Keras and Theano in the <a href="https://github.com/justinsvegliato/deep-jammer">project repository</a>.</p>


                </div>
            </div>
        </div>
    </article>

    <hr>

    <!-- Footer -->
    <footer>
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                    <ul class="list-inline text-center">
                        <li>
                            <a href="https://www.linkedin.com/in/sam-witty-46708572">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-linkedin fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                        <li>
                            <a href="https://github.com/SamWitty">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-github fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                        <li>
                            <a href="https://twitter.com/3300641658a4405">
                                <span class="fa-stack fa-lg">
                                    <i class="fa fa-circle fa-stack-2x"></i>
                                    <i class="fa fa-twitter fa-stack-1x fa-inverse"></i>
                                </span>
                            </a>
                        </li>
                    </ul>
                    <p class="copyright text-muted">Copyright &copy; Sam Witty 2018 </p>
                </div>
            </div>
        </div>
    </footer>

    <!-- jQuery -->
    <script src="vendor/jquery/jquery.min.js"></script>

    <!-- Bootstrap Core JavaScript -->
    <script src="vendor/bootstrap/js/bootstrap.min.js"></script>

    <!-- Contact Form JavaScript -->
    <script src="js/jqBootstrapValidation.js"></script>
    <script src="js/contact_me.js"></script>

    <!-- Theme JavaScript -->
    <script src="js/clean-blog.min.js"></script>

</body>

</html>
